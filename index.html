<!DOCTYPE html>
<!-- saved from url=(0026)https://han-sin.github.io/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <title>Zhichao's website</title>
  <meta name="author" content="Zhichao Han">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" href="https://han-sin.github.io/data/favicon/favicon.ico" type="image/x-icon">
  <link rel="stylesheet" type="text/css" href="./Zhichao&#39;s website_files/stylesheet.css">
</head>

<body data-new-gr-c-s-check-loaded="14.1235.0" data-gr-ext-installed="">
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    Zhichao Han
                  </p>
                  <p>
                    Hi, I'm Zhichao. This website is a brief introduction about myself.
                  </p>
                  <p>
                    In 2021, I received my Bachelor of Engineering degree from 
                     <a href="http://ckc.zju.edu.cn/">Chu Kochen Honors College</a> 
                     at <a href="https://www.zju.edu.cn/">Zhejiang University</a>. 
                    I am currently pursuing a Ph.D. in Robotics at the <a href="http://zju-fast.com/">Fast Lab</a>,  <a href="https://www.zju.edu.cn/">Zhejiang University</a>, 
                    under the supervision of renowned roboticist Professor <a href="http://zju-fast.com/research-group/fei-gao/">Fei Gao</a>.
                    My research interests include motion planning and robot learning.
                  </p>
                  <p style="text-align:left">
                  <a href="https://han-sin.github.io/data/profile/ZhichaoHan-contact.txt" style="margin-right: 20px;">Contact</a>
                  <a href="https://scholar.google.com/citations?user=5g-ZhmwAAAAJ&amp;hl=zh-CN">Google Scholar</a>
                </p>

                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="./Zhichao&#39;s website_files/hanzhichao.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="./Zhichao&#39;s website_files/hanzhichao.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          

          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <h2>Project</h2>
                  <p>
                    Below are some of the research projects I have been involved in, listed in chronological order.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>

        <tr> <td style="padding:10px;width:30%;vertical-align:middle">
          <div class="video-container" style="width: 330px; height: 186.0px;">
            <video width="100%" height="100%" muted="" autoplay="" loop="" playsinline="">
              <source src="data/aero.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
          </div>
        </td>
        <td style="padding:20px;width:70%;vertical-align:middle">
          <a href="https://han-sin.github.io/">
            <span class="papertitle">Reactive Aerobatic Flight via Reinforcement Learning</span>
          </a>
          <br>
          <strong>Zhichao Han</strong>, Xijie Huang, Zhuxiu Xu, Jiarui Zhang, Yuze Wu, Mingyang Wang, Tianyue Wu, Fei Gao
          <br>
          <em>IEEE Robotics and Automation Letters (RA-L)</em>, 2025, under review /
          <a href="https://han-sin.github.io/data/aero.pdf">Paper</a>
    <p style="text-align:justify;">
            This work pushes the boundaries of quadrotor maneuverability by employing a reinforcement learning framework to enable highly dynamic large-scale acrobatic flight.  Leveraging a lightweight neural network (inference time less than 1ms), our approach handles dynamically changing aerobatic points, achieving—for the first time—autonomous inverted flight through a moving gate, a maneuver challenging even for expert human pilots.  Traditional methods require seconds of pre-planning for such maneuvers, precluding real-time adaptation to dynamic environments.
          </p>
        </td>
        </tr>






              <tr> <td style="padding:10px;width:30%;vertical-align:middle">
          <div class="video-container" style="width: 330px; height: 186.0px;">
            <video width="100%" height="100%" muted="" autoplay="" loop="" playsinline="">
              <source src="data/e2e.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
          </div>
        </td>
        <td style="padding:20px;width:70%;vertical-align:middle">
          <a href="https://han-sin.github.io/">
            <span class="papertitle">Dynamically Feasible Trajectory Generation with Optimization Embedded
Networks for Autonomous Flight</span>
          </a>
          <br>
                  <br>
                  <strong>Zhichao Han*</strong>,
                  Long Xu*,
                  Liuao Pei,
                  Fei Gao
                  <br>
                  <em>IEEE Robotics and Automation Letters (RA-L)</em>, 2024, conditional acceptance /
                  <a href="https://han-sin.github.io/data/e2e.pdf">Paper</a>
    <p style="text-align:justify;">
                    This work introduces a depth-image based, end-to-end navigation policy.  
                   We leverage a motion primitive library to approximate the multi-modal distribution of optimal local trajectories. 
                  To guarantee dynamic feasibility and stable tracking at high speeds, 
                  our network outputs safety constraints rather than trajectories directly,
                   which are then used by an efficient spatio-temporal optimizer.
                     While seemingly hierarchical, this process is made differentiable using optimality conditions and 
                     the implicit function theorem, enabling end-to-end training directly on the final trajectory loss and 
                     preserving optimality.
                  </p>
                </td>
              </tr>

<tr>
  <td style="padding:10px;width:30%;vertical-align:middle;">
    <div class="video-container" style="width: 330px; height: 186.0px;">
      <video width="100%" height="100%" muted="" autoplay="" loop="">
        <source src="data/sr.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
    </div>
  </td>
  <td style="padding:20px;width:70%;vertical-align:middle;">
    <a href="https://han-sin.github.io/">
      <span class="papertitle">Hierarchically Depicting Vehicle Trajectory with Stability in Complex Environments</span>
    </a>
    <br><br>
    <strong>Zhichao Han*</strong>,
    Mengze Tian*,
    Zaitian Gongye,
    Donglai Xue,
    Jiaxi Xing,
    Qianhao Wang,
    Yuman Gao,
    Jingping Wang,
    Chao Xu,
    Fei Gao
    <br>
    <em>Science Robotics</em>, 2024, Accepted, waiting for publication 
    <!-- <a href="data/LF3PM.pdf">Paper</a> -->
    <p style="text-align:justify;">
      This work addresses two major challenges: the inefficiency of initial value search in complex environments and numerical instability caused by singularities in flat spaces.
      We propose a deep neural network that infers initial paths directly from environmental data, effectively decoupling computational complexity from environmental intricacy and ensuring temporal stability.
      To address singularities in flat spaces for nonholonomic robots, we introduce a pseudo-arclength mapping and a lightweight bilevel spatiotemporal trajectory representation, which fundamentally resolves the singularity problem and enables efficient, stable convergence even in complex tasks involving mode switching.
    </p>
  </td>
</tr>

          




<tr>
  <td style="padding:10px;width:30%;vertical-align:middle;">
    <div class="video-container" style="width: 330px; height: 186.0px;">
      <video width="100%" height="100%" muted="" autoplay="" loop="">
        <source src="data/tits_c.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
    </div>
  </td>
  <td style="padding:20px;width:70%;vertical-align:middle;">
    <a href="https://han-sin.github.io/">
      <span class="papertitle">An Efficient Spatial-Temporal Trajectory Planner for Autonomous Vehicles in Unstructured Environments</span>
    </a>
    <br><br>
    <strong>Zhichao Han*</strong>,
Yuwei Wu*, Tong Li, Lu Zhang, Liuao Pei,
Chengyang Li, Changjia Ma, Chao Xu, Shaojie Shen, Fei Gao
    <br>
    <em>IEEE Transactions on Intelligent Transportation Systems (T-ITS)</em>, 2023, published/
              <a href="https://han-sin.github.io/data/tits.pdf">Paper</a>
    <p style="text-align:justify;">
      Leveraging the differential flatness property of car-like robots, this work transforms full-state trajectory optimization into the flat output space, enabling efficient spatiotemporal planning under nonholonomic constraints. A convex approximation of the feasible space is employed to construct lightweight analytical geometric constraints for static obstacle avoidance. Additionally, the Minkowski difference is used to derive a signed lower bound on convex hull distances, which forms the basis for dynamic obstacle avoidance constraints.
    </p>
  </td>
</tr>


<tr>
  <td style="padding:10px;width:30%;vertical-align:middle;">
    <div class="video-container" style="width: 330px; height: 186.0px;">
      <video width="100%" height="100%" muted="" autoplay="" loop="">
        <source src="data/fastracing_c.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
    </div>
  </td>
  <td style="padding:20px;width:70%;vertical-align:middle;">
    <a href="https://han-sin.github.io/">
      <span class="papertitle">Fast-Racing: An Open-Source Strong Baseline for SE(3) Planning in Autonomous Drone Racing</span>
    </a>
    <br><br>
    <strong>Zhichao Han</strong>,
Zhepei Wang, Neng Pan, Yi Lin, Chao Xu, Fei Gao
    <br>
    <em>IEEE Robotics and Automation Letters (RA-L)</em>, 2021, published/
          <a href="https://han-sin.github.io/data/fastracing.pdf">Paper</a>
    <p style="text-align:justify;">
      To enhance quadrotor performance in cluttered environments, this work introduces a trajectory optimization method in SE(3) space that fully exploits the vehicle's agility, 
      enabling high-speed drone racing through complex scenarios. 
     This technology was applied to the   <a href="https://www.robomaster.com/en-US/robo/icra">DJI Artificial Intelligence Challenge</a>  (2022) and won the championship!
    </p>
  </td>
</tr>



<tr>
  <td style="padding:10px;width:30%;vertical-align:middle;">
    <div class="video-container" style="width: 330px; height: 186.0px;">
      <video width="100%" height="100%" muted="" autoplay="" loop="">
        <source src="data/fasttrack_c.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
    </div>
  </td>
  <td style="padding:20px;width:70%;vertical-align:middle;">
    <a href="https://han-sin.github.io/">
      <span class="papertitle">Fast-tracker: A robust aerial system for tracking agile target in cluttered environments</span>
    </a>
    <br><br>
    <strong>Zhichao Han*</strong>,
Ruibin Zhang*, Neng Pan*, Chao Xu, Fei Gao
    <br>
    <em>IEEE International Conference on Robotics and Automation (ICRA)</em>, 2021, published/
          <a href="https://han-sin.github.io/data/fasttrack.pdf">Paper</a>
    <p style="text-align:justify;">
   By predicting the target's trajectory and formulating a corresponding tracking planning problem, we successfully deployed the solution on a fully autonomous UAV system. This achievement was featured by the prominent media outlet IEEE Spectrum.
    </p>
  </td>
</tr>





<tr>
  <td style="padding:10px;width:30%;vertical-align:middle;">
    <div class="video-container" style="width: 330px; height: 186.0px;">
      <video width="100%" height="100%" muted="" autoplay="" loop="">
        <source src="data/ringrotor.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
    </div>
  </td>
  <td style="padding:20px;width:70%;vertical-align:middle;">
    <a href="https://han-sin.github.io/">
      <span class="papertitle">Shape-Adaptive Planning and Control for a Deformable Quadrotor</span>
    </a>
    <br><br>
    Yuze Wu*, <strong>Zhichao Han*</strong>, Xuankang Wu, Yuan Zhou, Junjie Wang, Zheng Fang, Fei Gao
    <br>
    <em>IEEE International Conference on Intelligent Robots and Systems (IROS)</em>, 2025, under review /
          <a href="https://han-sin.github.io/data/ringrotor.pdf">Paper</a>
    <p style="text-align:justify;">
   We developed a tailored trajectory planning model for morphable UAVs that fully exploits their structural adaptability, enabling autonomous shape transformation in response to environmental conditions and significantly improving navigation efficiency.
    </p>
  </td>
</tr>



<tr>
  <td style="padding:10px;width:30%;vertical-align:middle;">
    <div class="video-container" style="width: 330px; height: 186.0px;">
      <video width="100%" height="100%" muted="" autoplay="" loop="">
        <source src="data/trailer.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
    </div>
  </td>
  <td style="padding:20px;width:70%;vertical-align:middle;">
    <a href="https://han-sin.github.io/">
      <span class="papertitle">Tracailer: An Efficient Trajectory Planner for Tractor-Trailer Vehicles in Unstructured Environments</span>
    </a>
    <br><br>
    Long Xu, Kaixin Chai, Boyuan An, Jiaxiang Gan, Qianhao Wang, Yuan Zhou, Xiaoying Li, Junxiao Lin, <strong>Zhichao Han</strong>, Chao Xu, Yanjun Cao, Fei Gao
    <br>
    <em>IEEE Transactions on Automation Science and Engineering (T-ASE)</em>, 2024, under review /
          <a href="https://han-sin.github.io/data/trailer.pdf">Paper</a>
    <p style="text-align:justify;">
   This work investigates trajectory generation for systems with deformable characteristics arising from passive joints. Leveraging the augmented Lagrangian method and signed distance fields, we developed an efficient motion planner for tractor-trailer robots.
    </p>
  </td>
</tr>






<tr>
  <td style="padding:10px;width:30%;vertical-align:middle;">
    <div class="video-container" style="width: 330px; height: 186.0px;">
      <video width="100%" height="100%" muted="" autoplay="" loop="">
        <source src="data/CollaborativePlanning.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
    </div>
  </td>
  <td style="padding:20px;width:70%;vertical-align:middle;">
    <a href="https://han-sin.github.io/">
      <span class="papertitle">Collaborative Planning for Catching and Transporting Objects in Unstructured Environments</span>
    </a>
    <br><br>
    Liuao Pei, Junxiao Lin, <strong>Zhichao Han</strong>, Lun Quan, Yanjun Cao, Chao Xu, Fei Gao
    <br>
    <em>IEEE Robotics and Automation Letters (RA-L) </em>, 2023, published /
          <a href="https://han-sin.github.io/data/CollaborativePlanning.pdf">Paper</a>
    <p style="text-align:justify;">
   This work achieves centralized coordination of wheeled robots and successfully demonstrates dynamic object capture and transportation.
    </p>
  </td>
</tr>






<tr>
  <td style="padding:10px;width:30%;vertical-align:middle;">
    <div class="video-container" style="width: 330px; height: 186.0px;">
      <video width="100%" height="100%" muted="" autoplay="" loop="">
        <source src="data/Uneven.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
    </div>
  </td>
  <td style="padding:20px;width:70%;vertical-align:middle;">
    <a href="https://han-sin.github.io/">
      <span class="papertitle">An Efficient Trajectory Planner for Car-Like Robots on Uneven Terrain</span>
    </a>
    <br><br>
    Long Xu, Kaixin Chai, <strong>Zhichao Han</strong>, Hong Liu, Chao Xu, Yanjun Cao, Fei Gao
    <br>
    <em>IEEE International Conference on Intelligent Robots and Systems (IROS) </em>, 2023, published /
          <a href="https://han-sin.github.io/data/Uneven.pdf">Paper</a>
    <p style="text-align:justify;">
   This work implements a  SE(2) traversability assessment algorithm, 
   which serves as the foundation for a local navigation framework for wheeled robots operating in uneven terrain.
    </p>
  </td>
</tr>


<tr>
  <td style="padding:10px;width:30%;vertical-align:middle;">
    <div class="video-container" style="width: 330px; height: 186.0px;">
      <video width="100%" height="100%" muted="" autoplay="" loop="">
        <source src="data/Decentralized.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
    </div>
  </td>
  <td style="padding:20px;width:70%;vertical-align:middle;">
    <a href="https://han-sin.github.io/">
      <span class="papertitle">Decentralized planning for car-like robotic swarm in unstructured environments</span>
    </a>
    <br><br>
    Changjia Ma,
<strong>Zhichao Han</strong>,
Tingrui Zhang,
Jingping Wang, Long Xu
, Chengyang Li
, Chao Xu, Fei Gao
    <br>
    <em>IEEE International Conference on Intelligent Robots and Systems (IROS) </em>, 2023, published /
          <a href="https://han-sin.github.io/data/Decentralized.pdf">Paper</a>
    <p style="text-align:justify;">
This work implements a fully autonomous, distributed swarm of wheeled robots  in complex environments.
    </p>
  </td>
</tr>






        </tbody>
          </table>
          <!-- Thanks -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:center;font-size:small;">
                    Thanks for the website template offered by <a href="https://github.com/jonbarron/jonbarron_website">Jon
                      Barron</a>.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
  </tbody></table>


</body><grammarly-desktop-integration data-grammarly-shadow-root="true"><template shadowrootmode="open"><style>
      div.grammarly-desktop-integration {
        position: absolute;
        width: 1px;
        height: 1px;
        padding: 0;
        margin: -1px;
        overflow: hidden;
        clip: rect(0, 0, 0, 0);
        white-space: nowrap;
        border: 0;
        -moz-user-select: none;
        -webkit-user-select: none;
        -ms-user-select:none;
        user-select:none;
      }

      div.grammarly-desktop-integration:before {
        content: attr(data-content);
      }
    </style><div aria-label="grammarly-integration" role="group" tabindex="-1" class="grammarly-desktop-integration" data-content="{&quot;mode&quot;:&quot;full&quot;,&quot;isActive&quot;:true,&quot;isUserDisabled&quot;:false}"></div></template></grammarly-desktop-integration></html>
